{"cells": [{"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": "from Bio import Entrez\nimport pandas as pd\nfrom xml.dom.minidom import parse\nimport xml.dom.minidom\nimport pickle\nimport json\nfrom pymed import PubMed\nimport requests\nimport datetime\nimport os\nimport pyspark\nfrom pyspark import SparkConf, SparkContext\nimport sys\nfrom collections import defaultdict\n\npubmed = PubMed(tool=\"MyTool\", email=\"jefflovejoy1314@gmail.com\")"}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": "query_string = '(\"neoplasms\"[MeSH Terms] OR \"neoplasms\"[All Fields] OR \"cancer\"[All Fields]) AND (\"2009/11/24\"[PDat] : \"2019/11/21\"[PDat])'\nresults = pubmed.query(query_string, max_results=3965593)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "file_number = 0\n\ninfo_dict = {'pubmed_id': [], 'authors': [], 'keywords':[], 'abstract':[],'publication_date':[],'title':[],'results':[],'doi':[], \n             'journal':[]}\n\n\nfor i in results:\n#     print(len(info_dict['pubmed_id']))\n    for key in list(info_dict.keys()):\n        try:\n            if key == 'authors':\n                au = i.authors\n                auinfo = []\n                for x in au: \n                    name = str(x['firstname']) + ' ' + str(x['lastname'])\n                    affiliation = x['affiliation']\n                    auinfo.append(f'{name}-{affiliation}')\n                info_dict[key].append(';'.join(auinfo))\n            elif key == 'pubmed_id':\n                info_dict[key].append(str(i.pubmed_id.split('\\n')[0]))\n            else:\n                info_dict[key].append(getattr(i,key))\n\n        except:\n            info_dict[key].append(None)\n            \n    if len(info_dict['pubmed_id']) == 15000:\n        pd.DataFrame(info_dict).to_csv(f'cancer/cancer_{file_number}.csv')\n        info_dict = {'pubmed_id': [], 'authors': [], 'keywords':[], 'abstract':[],'publication_date':[],'title':[],'results':[],'doi':[], \n             'journal':[]}\n        file_number += 1\n\n        print(file_number)\n        "}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "sc = pyspark.SparkContext.getOrCreate()\nsc.textFile('gs://project_rong/cancer/gcp_codes.txt')\n\npd.read_csv('cancer/cancer_100.csv')\n! gsutil cp cancer/cancer_1.csv gs://project_rong/cancer/cancer_1.csv"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# combine all the files\ntotal_file = pd.read_csv('cancer/cancer_0.csv')\n\nfor r,d,f in os.walk('cancer'): \n    for fn in f:\n        if fn == 'cancer_0.csv':\n            continue\n        else: \n            file1 = pd.read_csv(f'cancer/{fn}')\n            total_file = pd.concat([total_file, file1], ignore_index= True)\n    \n        \npd.DataFrame(total_file).to_csv('cancer/cancer_total.csv')"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "! gsutil cp cancer/cancer_total.csv gs://project_rong/cancer/cancer_total.csv\n! gsutil cp gs://project_rong/bigdata-d7b584548bdd.json bigdata-d7b584548bdd.json"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# parse info for authors\nimport pandas_gbq\nfrom google.oauth2 import service_account\n\ncredentials = service_account.Credentials.from_service_account_file('bigdata-d7b584548bdd.json')\npandas_gbq.context.credentials = credentials\npandas_gbq.context.project = \"bigdata-259800\"\n\n\nau_pair = []\n\nfor au_group in useful_au:\n    au_pairlist = list(permutations([x.replace('\\n', ' ') for x in au_group.split(\";\")],2))\n    au_pair.extend(au_pairlist)\n\nedges = pd.DataFrame({'source': [i[0] for i in au_pair], 'target':[i[1] for i in au_pair]})\nnodes = pd.DataFrame({'au_nodes': au_nodes_list})\n\n\nnodes.to_csv('cancer/au_nodes.csv')\npandas_gbq.to_gbq(edges, 'authorinfo.author_edges', project_id= \"bigdata-259800\")\npandas_gbq.to_gbq(nodes, 'authorinfo.author_nodes', project_id= \"bigdata-259800\")\n\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.9"}}, "nbformat": 4, "nbformat_minor": 2}